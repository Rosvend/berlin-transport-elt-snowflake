# Use the official Airflow image as base
FROM apache/airflow:2.7.1-python3.10

# Switch to root to install system dependencies
USER root

# Install system dependencies
RUN apt-get update \
  && apt-get install -y --no-install-recommends \
         curl \
         build-essential \
  && apt-get autoremove -yqq --purge \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

# Switch back to airflow user
USER airflow

# Copy requirements file
COPY requirements.txt /requirements.txt

# Install Python dependencies
RUN pip install --no-cache-dir -r /requirements.txt

# Create necessary directories
RUN mkdir -p /opt/airflow/extract \
    && mkdir -p /opt/airflow/config \
    && mkdir -p /opt/airflow/data

# Set the working directory
WORKDIR /opt/airflow

# Copy project files
COPY --chown=airflow:root airflow/dags/ /opt/airflow/dags/
COPY --chown=airflow:root extract/ /opt/airflow/extract/
COPY --chown=airflow:root config/ /opt/airflow/config/
COPY --chown=airflow:root dbt/ /opt/airflow/dbt/
COPY --chown=airflow:root scripts/ /opt/airflow/scripts/

# Initialize the database (this will be run when container starts)
# But we need to ensure it's done before starting other services
COPY --chown=airflow:root docker/init-airflow.sh /opt/airflow/init-airflow.sh
RUN chmod +x /opt/airflow/init-airflow.sh

# Set environment variables
ENV AIRFLOW__CORE__LOAD_EXAMPLES=False
ENV AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True

# Expose port
EXPOSE 8080
COPY --chown=airflow:root docker/init-airflow.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
